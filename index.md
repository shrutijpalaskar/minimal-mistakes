---
layout: page
title: Welcome
tags: [shruti, palaskar, home, cmu, speech recognition, machine learning, natural language processing, graduate, carnegie mellon]
modified: 2018-11-27T20:53:07.573882-04:00
comments: false
---

Hi!

I am a first year PhD student at the [Language Technologies Institute](http://www.lti.cs.cmu.edu/) of the School of Computer Science at [Carnegie Mellon University](http://www.cmu.edu/). My research interests lie in the areas of multimodal machine learning, speech recognition and natural language generation. I am fortunate to be advised by [Prof. Florian Metze](http://www.cs.cmu.edu/~fmetze/interACT/Home.html).

Prior to starting my PhD, I received my Masters in Language Technologies degree from LTI, CMU. During my master's, I spent two wonderful summers as part of the JHU Frederick Jelinek Summer Workshops [JSALT](https://www.clsp.jhu.edu/workshops/18-workshop/) working on multimodal learning. Before that, I received my bachelor's degree in Computer Engineering from [Pune Institute of Computer Technology](www.pict.edu) in 2016. 

----

<h3 align="center">News</h3>
<table class='news-table'>
    <col width="20%">
    <col width="80%">
    <tr>
        <td valign="top"><strong>[Nov 2018]</strong></td>
        <td>The <b>How2 dataset</b> of open-domain instructional videos has been released!
        Read more on <a href="https://github.com/srvk/how2-dataset">how2 download</a>.
        Email me for any questions :-)
        </td>
    </tr>
    <tr>
        <td valign="top"><strong>[Nov 2018]</strong></td>
        <td>Our paper on the <b>How2 dataset</b> has been accepted at the <a href="https://nips2018vigil.github.io">NeurIPS 2018 ViGIL workshop</a>. Here is a <a href="https://arxiv.org/pdf/1811.00347.pdf">link </a>to the paper.</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Nov 2018]</strong></td>
        <td>Our paper on Multimodal Abstractive Summarization of Open-Domain Videos has been accepted at the <a href="https://nips2018vigil.github.io">NeurIPS 2018 ViGIL workshop</a> for <b>Spotlight</b> presentation!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Nov 2018]</strong></td>
        <td>Reviewing for the 7th Dialog State Tracking Challenge <a href="http://workshop.colips.org/dstc7/tracks.html">Audio-Visual Scene-aware Dialog</a> track</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Oct 2018]</strong></td>
        <td><a href="http://www.cs.cmu.edu/~ramons/">Ramon</a> and I won the <b>first place</b> in the 7th Dialog State Tracking Challenge Audio Visual Scene-aware Dialog track</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Sep 2018]</strong></td>
        <td>Very happy to be a part of the <a href="https://sites.google.com/view/yfrsw2018/home">Young Female Researchers in Speech, Science and Technology Workshop</a> at Interspeech 2018 as a <b>PhD student panelist</b></td>
    </tr>
    <tr>
        <td valign="top"><strong>[Sep 2018]</strong></td>
        <td>Our paper on <a href="https://arxiv.org/abs/1807.09597">Acoustic-to-Word Speech Recognition</a> is accepted at <a href="http://www.slt2018.org">SLT 2018</a></td>
    </tr>
    <tr>
        <td valign="top"><strong>[Jul 2018]</strong></td>
        <td>Received the 2018-2019 <b>Graduate Research Fellowship</b> from the <a href="https://www.cs.cmu.edu/cmlh-fellows_2018">Center for Machine Learning and Health</a>. Thank you CMLH!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[June 2018]</strong></td>
        <td>Excited to start the JSALT 2018 workshop on Grounded Sequence to Sequence Transduction at JHU!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[May 2018]</strong></td>
        <td>Graduated from the Masters program at CMU, yay!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Feb 2018]</strong></td>
        <td>Our paper on <a href="https://arxiv.org/abs/1804.09713">Multimodal Speech Recognition</a> got accepted at ICASSP 2018!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Sep 2017]</strong></td>
        <td>Excited to attend the Young Female Researchers in Speech Workshop at Interspeech 2017</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Jul 2017]</strong></td>
        <td>Excited to start the JSALT 2017 workshop as part of the Speaking Rosetta Stone team at CMU!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Sep 2016]</strong></td>
        <td>Received the CMU LTI <b>Graduate Research Fellowship</b> for acamedic years 2016-2018</td>
    </tr>
</table>
