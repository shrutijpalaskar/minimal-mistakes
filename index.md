---
layout: page
title: Welcome
tags: [shruti, palaskar, home, cmu, speech recognition, machine learning, natural language processing, graduate, carnegie mellon]
modified: 2014-08-08T20:53:07.573882-04:00
comments: false
---

Hi!

I am a first year PhD student at the [Language Technologies Institute](http://www.lti.cs.cmu.edu/) of the School of Computer Science at [Carnegie Mellon University](http://www.cmu.edu/). My research interests lie in the areas of multimodal machine learning, speech recognition and natural language processing. I am fortunate to be advised by [Prof. Florian Metze](http://www.cs.cmu.edu/~fmetze/interACT/Home.html).

My long-term research goal is to enable machines to learn from multiple modalities of data like text, audio, video, semantics, and draw inferences and make decisions using those, as humans naturally do.
Currently, I am working on building deep learning models for speech recognition, video understanding and dialog summarization from multimodal data like open-domain videos from YouTube, the [How2 dataset](https://github.com/srvk/how2-dataset), (containing audio, video, text, summary, and topics) or doctor-patient dialogs (containing audio, text, and semantics).

Prior to starting my PhD, I received my Masters in Language Technologies degree from LTI, CMU. During my masters, I spent two wonderful summers as part of the Frederick Jelinek Summer Workshops [JSALT](https://www.clsp.jhu.edu/workshops/18-workshop/) working on multimodal learning: I worked with [Prof. Emmanuel Dupoux](http://www.lscp.net/persons/dupoux/) and [Prof. Odette Scharenborg](https://scholar.google.nl/citations?user=hyz2eHkAAAAJ&hl=nl) on the [Speaking Rosetta Team](http://129.199.81.135/cmuworkshop/) in 2017
and with [Prof. Lucia Specia](https://staffwww.dcs.shef.ac.uk/people/L.Specia/), [Prof. Raman Arora](http://www.cs.jhu.edu/~raman/Home.html) on the [Grounded Sequence to Sequence Transduction Team](https://www.clsp.jhu.edu/workshops/18-workshop/grounded-sequence-sequence-transduction/) in 2018. 

I received my bachelor's degree in Computer Engineering from [Pune Institute of Computer Technology](www.pict.edu) in 2016. During my undergrad, I was fortunate to work on computer vision problems with [Dr. Hyunsung Park](https://sites.google.com/site/hyunsung/) and [Prof. Ramesh Raskar](http://web.media.mit.edu/~raskar/) at the MIT Media Lab mentored [REDX Innovation
Labs](http://redx.io), on machine translation with [Prof. Ganesh Ramakrishnan](https://www.cse.iitb.ac.in/~ganesh/) at [IIT
Bombay](https://www.cse.iitb.ac.in) and on recommender systems with [Harshed Saykhedkar](https://www.linkedin.com/in/harshadss/?originalSubdomain=in) from a startup [Sokrati Technologies](https://sokrati.com).


----

<h3 align="center">News</h3>
<table class='news-table'>
    <col width="18%">
    <col width="82%">
    <tr>
        <td valign="top"><strong>[Nov 2018]</strong></td>
        <td>The <b>How2 dataset</b> of open-domain instructional videos has been released!</td>
        <td>Checkout our GitHub page for instructions on <a href="https://github.com/srvk/how2-dataset">how2 download</a>.
        Email me for any questions :-)
        </td>
    </tr>
    <tr>
        <td valign="top"><strong>[Nov 2018]</strong></td>
        <td>Our paper on the <b>How2 dataset</b> has been accepted at the <a href="https://nips2018vigil.github.io">NeurIPS 2018 ViGIL workshop</a>. Here is a <a href="https://arxiv.org/pdf/1811.00347.pdf">link </a>to the paper.</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Nov 2018]</strong></td>
        <td>Our paper on Multimodal Abstractive Summarization of Open-Domain Videos has been accepted at the <a href="https://nips2018vigil.github.io">NeurIPS 2018 ViGIL workshop</a> for <b>Spotlight</b> presentation!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Nov 2018]</strong></td>
        <td>Reviewing for the 7th Dialog State Tracking Challenge <a href="http://workshop.colips.org/dstc7/tracks.html">Audio-Visual Scene-aware Dialog</a> track</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Oct 2018]</strong></td>
        <td><a href="http://www.cs.cmu.edu/~ramons/">Ramon</a> and I won the first place in the 7th Dialog State Tracking Challenge Audio Visual Scene-aware Dialog</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Sep 2018]</strong></td>
        <td>Very happy to be a part of the <a href="https://sites.google.com/view/yfrsw2018/home">Young Female Researchers in Speech, Science and Technology Workshop</a> at Interspeech 2018 as a <b>PhD student panelist</b></td>
    </tr>
    <tr>
        <td valign="top"><strong>[Sep 2018]</strong></td>
        <td>Our paper on <a href="https://arxiv.org/abs/1807.09597">Acoustic-to-Word Speech Recognition with Sequence-to-Sequence Models</a> is accepted at <a href="http://www.slt2018.org">SLT 2018</a></td>
    </tr>
    <tr>
        <td valign="top"><strong>[Jul 2018]</strong></td>
        <td>Received the 2018-2019 Graduate Research Fellowship from the <a href="">Center for Machine Learning and Health</a>. Thank you CMLH!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[June 2018]</strong></td>
        <td>Excited to start the JSALT 2018 workshop on Grounded Sequence to Sequence Transduction at JHU!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[May 2018]</strong></td>
        <td>Graduated from the Masters program at CMU, yay!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Feb 2018]</strong></td>
        <td>Our paper on <a href="https://arxiv.org/abs/1804.09713">End-to-End Multimodal Speech Recognition</a> got accepted at ICASSP 2018!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Sep 2017]</strong></td>
        <td>Excited to attend the Young Female Researchers in Speech Workshop at Interspeech 2017 and present our work on Multimodal Speech Recognition and Summarization</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Jul 2017]</strong></td>
        <td>Excited to start the JSALT 2018 workshop as part of the Speaking Rosetta Stone team at CMU!</td>
    </tr>
    <tr>
        <td valign="top"><strong>[Sep 2016]</strong></td>
        <td>Awared the CMU, LTI Graduate Fellowship for acamedic years 2016-2018</td>
    </tr>
</table>
